{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Operations and Parallel Mapping\n",
    "\n",
    "Parallel processing of collections is important\n",
    "* one the main applications of parallelism today\n",
    "We examine conditions when this can be done\n",
    "- properties of collections: ability to split, combine\n",
    "- properties of operations: associativity, independence\n",
    "\n",
    "Operations on collections are key to functional programming\n",
    "\n",
    "map: apply function to each element\n",
    "- `List(1,3,8).map(x => x*x) == List(1, 9, 64)`\n",
    "\n",
    "fold: combine elements with a given operation\n",
    "- `List(1,3,8).fold(100)((s,x) => s + x) == 112`\n",
    "\n",
    "scan: combine folds of all list prefixes\n",
    "\n",
    "- `List(1,3,8).scan(100)((s,x) => s + x) == List(100, 101, 104, 112)`\n",
    "\n",
    "\n",
    "These operations are even more important for parallel than sequential collections: \n",
    "they encapsulate more complex algorithms.\n",
    "\n",
    "You can think of `scan` as applying `fold` to all list prefixes, or alternatively, as recording the intermediate results\n",
    "of computing the fold of a list. Let's apply now `scan` to\n",
    "the same input list and to the same initial elements\n",
    "in the operation of summation. What we will get is the sequence that has\n",
    "the length one more than your original sequence and contains elements 100,\n",
    "so the initial element. Then 101, so your initial element\n",
    "plus the first element of the list, then 104 obtained by adding 3, and\n",
    "then after adding 8, we obtain 112. \n",
    "\n",
    "\n",
    "So these operations exist in the sequential case already, but they become even more important\n",
    "in case of parallel operations, because in that case, implementing them from scratch is more difficult. So there's even more value in reusing\n",
    "such implementations from the library. \n",
    "We have been using list to specify the intended result of these operations, but in fact, lists themselves are not a very good implementation of parallel collections. \n",
    "Because we cannot efficiently split them in half since we would need to find the position of the middle of the list. \n",
    "And it is also not efficient to combine them because concatenation takes linear time. For simplicity, here, we will consider two alternatives to lists.\n",
    "\n",
    "\n",
    "We use `List` to specify the results of operations.\n",
    "\n",
    "Lists are not good for parallel implementations because we cannot efficiently\n",
    "- split them in half (need to search for the middle)\n",
    "- combine them (concatenation needs linear time)\n",
    "\n",
    "We use for now these alternatives\n",
    "- arrays: imperative (recall array sum)\n",
    "- trees: can be implemented functionally\n",
    "\n",
    "\n",
    "Subsequent lectures examine Scala’s parallel collection libraries\n",
    "- includes many more data structures, implemented efficiently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map: Meaning and Properties\n",
    "\n",
    "Map applies a given function to each list element\n",
    "```scala\n",
    "List(1,3,8).map(x => x*x) == List(1, 9, 64)\n",
    "```\n",
    "`List(a1, a2, …, an).map(f) == List(f(a1), f(a2), …, f(an))`\n",
    "\n",
    "Properties to keep in mind:\n",
    "- `list.map(x => x) == list`\n",
    "- `list.map(f.compose(g)) == list.map(g).map(f)`\n",
    "\n",
    "Recall that `(f.compose(g))(x) = f(g(x))`.\n",
    "\n",
    "Let's write a sequential map function on lists.\n",
    "```scala\n",
    "def mapSeq[A,B](lst: List[A], f : A => B): List[B] = lst match {\n",
    "case Nil => Nil\n",
    "case h :: t => f(h) :: mapSeq(t,f)\n",
    "}\n",
    "```\n",
    "We would like a version that parallelizes\n",
    "- computations of $f(h)$ for different elements $h$\n",
    "- finding the elements themselves (list is not a good choice)\n",
    "\n",
    "\n",
    "Now we would like to have parallel\n",
    "versions of such map operation, that means that we would like to perform computations of f applied to different list elements in parallel. And we would also like to parallelize\n",
    "the transformation of the list itself, that means that the choice of list is no longer ideal. Because even finding the middle\n",
    "element of the list is already linear, so we would not be able to parallelize\n",
    "operation on long lists that have not yet achieve operation. We will therefore start by looking at implementations of maps on arrays. Here's one signature of such an operation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mmapASegSeq\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mapASegSeq[A,B](inp: Array[A], left: Int, right: Int, f : A => B,\n",
    "out: Array[B]) = {\n",
    "// Writes to out(i) for left <= i <= right-1\n",
    "var i= left\n",
    "while (i < right) {\n",
    "out(i)= f(inp(i))\n",
    "i= i+1\n",
    "} }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would take an input array, denoted by\n",
    "`inp`, and it also takes this argument, an output array to which\n",
    "the results should be written. To indicate which part of\n",
    "the array should be processed, we have indices `left` and `right`. And the processing should start\n",
    "at left and stop at `right-1`. The function to be applied is again passed as argument, this is the function f. Let's look first at sequential\n",
    "implementation of such function. We can do that using a simple while loop that starts from left, and then right, the output, right to the output array, the result of input of i for which function f is applied. Then we do that for increasingly large index i going from left up to and not including right. So the effect of this function is that the content of the out array is going to be changed between this, left and right-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36min\u001b[39m: \u001b[32mArray\u001b[39m[\u001b[32mInt\u001b[39m] = \u001b[33mArray\u001b[39m(\u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m, \u001b[32m6\u001b[39m)\n",
       "\u001b[36mout\u001b[39m: \u001b[32mArray\u001b[39m[\u001b[32mInt\u001b[39m] = \u001b[33mArray\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m9\u001b[39m, \u001b[32m16\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m)\n",
       "\u001b[36mf\u001b[39m: \u001b[32mInt\u001b[39m => \u001b[32mInt\u001b[39m = ammonite.$sess.cmd1$Helper$$Lambda$2011/0x9abc2028@1f7a0ec\n",
       "\u001b[36mres1_4\u001b[39m: \u001b[32mArray\u001b[39m[\u001b[32mInt\u001b[39m] = \u001b[33mArray\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m9\u001b[39m, \u001b[32m16\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val in = Array(2,3,4,5,6)\n",
    "val out = Array(0,0,0,0,0)\n",
    "val f = (x:Int) => x*x\n",
    "mapASegSeq(in,1,3,f,out)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we do this in parallel?\n",
    "Let's use the `parallel` construct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```scala\n",
    "def mapASegPar[A,B](inp: Array[A], left: Int, right: Int, f : A => B,\n",
    "out: Array[B]): Unit = {\n",
    "// Writes to out(i) for left <= i <= right-1\n",
    "if (right - left < threshold)\n",
    "mapASegSeq(inp, left, right, f, out)\n",
    "else {\n",
    "val mid = left + (right - left)/2\n",
    "parallel(mapASegPar(inp, left, mid, f, out),\n",
    "mapASegPar(inp, mid, right, f, out))\n",
    "}\n",
    "}\n",
    "```\n",
    "When the difference between the left index\n",
    "and the right index is small enough, below some threshold, then we can invoke the\n",
    "function that we have defined previously. Otherwise, we compute\n",
    "the middle element and then we invoke the functions recursively from\n",
    "left to middle and from middle to right. There are two things that we\n",
    "need to pay attention to. One is that we are now invoking, in parallel, computations that\n",
    "are writing output to some array. It means that we need to\n",
    "be careful that parallel operation write to disjoint\n",
    "parts of the memory. \n",
    "\n",
    "In this case, what these codes are writing\n",
    "to are elements of the out array, so we need to track to which\n",
    "indices these codes are writing. And here we have a specification\n",
    "returning as an informal comment saying that our recursive function,\n",
    "just like the sequential counterpart. Writes to element out(i) for\n",
    "indices i between and including left, and\n",
    "up to and including right-1. Because of this property,\n",
    "we see that this recursive calls, in fact, will not interfere,\n",
    "because the highest element to which the first argument of\n",
    "parallel will write is mid minus 1. And the first element to which\n",
    "the second call will write is mid. Moreover, we see that if we assume\n",
    "the specification holds for these calls, then the specification\n",
    "will also hold for the entire function. So by induction, we can actually verify that this property\n",
    "that we have written in comments holds. \n",
    "\n",
    "\n",
    "\n",
    "In terms of performance, another point\n",
    "that we need to take into account is that this threshold needs to be large enough. This is particularly important for an example such as this, where the only thing that we are doing is\n",
    "writing certain elements of the array. \n",
    "\n",
    "If the function f is relatively simple,\n",
    "then performing this write to one index of\n",
    "an array is going to be several orders of magnitude cheaper than invoking parallel computations? So the overhead of parallelization\n",
    "will need to be somehow amortized over the number of times we are invoking these\n",
    "writes to individual indices of the array. That's why threshold needs to be several orders of magnitude as well. Once we have defined such parallel maps, we can then use it for various concrete functions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of using mapASegPar: pointwise exponent\n",
    "Raise each array element to power $p$:\n",
    "\n",
    "$Array(a1, a2, . . . , an) \\leftarrow Array(|a1|^p, |a2|^p, . . . , |an|^p)$\n",
    "We can use previously defined higher-order functions:\n",
    "\n",
    "```scala\n",
    "val p: Double = 1.5\n",
    "def f(x: Int): Double = power(x, p)\n",
    "mapASegSeq(inp, 0, inp.length, f, out) // sequential\n",
    "mapASegPar(inp, 0, inp.length, f, out) // parallel\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions on performance:\n",
    "\n",
    "- are there performance gains from parallel execution\n",
    "- performance of re-using higher-order functions vs re-implementing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential pointwise exponent written from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mmath.pow\n",
       "\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mnormsOf\u001b[39m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math.pow\n",
    "def normsOf(inp: Array[Int], p: Double,\n",
    "left: Int, right: Int,\n",
    "out: Array[Double]): Unit = {\n",
    "var i= left\n",
    "while (i < right) {\n",
    "out(i)= pow(inp(i),p)\n",
    "i= i+1\n",
    "}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel pointwise exponent written from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```scala\n",
    "def normsOfPar(inp: Array[Int], p: Double,\n",
    "left: Int, right: Int,\n",
    "out: Array[Double]): Unit = {\n",
    "if (right - left < threshold) {\n",
    "var i= left\n",
    "while (i < right) {\n",
    "out(i)= power(inp(i),p)\n",
    "i= i+1\n",
    "}\n",
    "} else {\n",
    "val mid = left + (right - left)/2\n",
    "parallel(normsOfPar(inp, p, left, mid, out),\n",
    "normsOfPar(inp, p, mid, right, out))\n",
    "}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, what do you think is the relative\n",
    "performance of these different versions? \n",
    "How much performance improvement do you expect from:\n",
    "\n",
    "- inlining the higher-order function of map\n",
    "- parallelizing over several cores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- inp.length = 2000000\n",
    "- threshold = 10000\n",
    "- Intel(R) Core(TM) i7-3770K CPU @ 3.50GHz (4-core, 8 HW threads), 16GB RAM\n",
    "|expression | time(ms)|\n",
    "|-----------|----------|\n",
    "|mapASegSeq(inp, 0, inp.length, f, out)| 174.17|\n",
    "|mapASegPar(inp, 0, inp.length, f, out)| 28.93|\n",
    "|normsOfSeq(inp, p, 0, inp.length, out)| 166.84|\n",
    "|normsOfPar(inp, p, 0, inp.length, out)| 28.17|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Parallelization pays off\n",
    "* Manually removing higher-order functions does not pay off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel map on immutable trees\n",
    "Consider trees where\n",
    "- leaves store array segments\n",
    "- non-leaf node stores two subtrees\n",
    "\n",
    "```scala\n",
    "sealed abstract class Tree[A] { val size: Int }\n",
    "case class Leaf[A](a: Array[A]) extends Tree[A] {\n",
    "override val size = a.size\n",
    "}\n",
    "case class Node[A](l: Tree[A], r: Tree[A]) extends Tree[A] {\n",
    "override val size = l.size + r.size\n",
    "}\n",
    "```\n",
    "Assume that our trees are balanced: we can explore branches in parallel.\n",
    "\n",
    "We will consider trees whose leaves store arrays segments and whose non leaf nodes contain references to left and to right sub tree. It is also going to be convenient for both leaves and non leaves to store the total number of elements. \n",
    "We will be assuming that our trees are approximately balanced. That will allow us to explore the branches in parallel while obtaining benefits of parallelization.\n",
    "\n",
    "Here is an implementation of paralle map on tree.\n",
    "```scala\n",
    "def mapTreePar[A:Manifest,B:Manifest](t: Tree[A], f: A => B) : Tree[B] =\n",
    "t match {\n",
    "case Leaf(a) => {\n",
    "val len = a.length; val b = new Array[B](len)\n",
    "var i= 0\n",
    "while (i < len) { b(i)= f(a(i)); i= i + 1 }\n",
    "Leaf(b) }\n",
    "case Node(l,r) => {\n",
    "val (lb,rb) = parallel(mapTreePar(l,f), mapTreePar(r,f))\n",
    "Node(lb, rb) }\n",
    "}\n",
    "```\n",
    "Speedup and performance similar as for the array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrays:\n",
    "\n",
    "- (+) random access to elements, on shared memory can share array\n",
    "- (+) good memory locality\n",
    "- (-) imperative: must ensure parallel tasks write to disjoint parts\n",
    "- (-) expensive to concatenate\n",
    "\n",
    "Immutable trees:\n",
    "* (+) purely functional, produce new trees, keep old ones\n",
    "* (+) no need to worry about disjointness of writes by parallel tasks\n",
    "* (+) efficient to combine two trees\n",
    "* (-) high memory allocation overhead\n",
    "* (-) bad locality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is instructive to compare using\n",
    "arrays versus basically immutable trees as collections on which we\n",
    "perform operations such as map. \n",
    "\n",
    "Arrays are very appealingbecause of their simplicity and because we can access\n",
    "elements in arbitrary order. \n",
    "When we have tasks that are executing on\n",
    "the same shared memory, that means we just need to pass the pointer or reference to the beginning of the array. And some indication of\n",
    "which indices of the array, appropriate task is suppose to process. \n",
    "Once we are processing a particular region of the array, because array elements are stored continuously in memory, we obtain good memory locality. \n",
    "On the other hand, because we need to\n",
    "create these arrays in an imperative way, we have to be careful that tasks\n",
    "that are executing in parallel write to disjoint parts of the array. Otherwise, we will obtain unpredictable results that depend on the order in which the writes are performed. That's one disadvantage of arrays. And another disadvantage is that if we obtain these arrays into completely different computations and\n",
    "we later want to put them together, they will necessarily have to copy some parts of the array. \n",
    "\n",
    "It is interesting to compare the properties of arrays with properties of immutable trees. \n",
    "\n",
    "In this approach, we have seen that we produce new trees as the result of operations such as map and we keep the old ones. That means that we can continue using the old versions of data which is useful for many applications. Moreover, because operations such as map produces new trees, it is easier to ensure\n",
    "that it does not write to the same parts of memory as some other operation that's executing in parallel. \n",
    "Next, it is easy to combine two trees\n",
    "because all we need to do is create a new node that has two other trees is, certain trees. Even if we need to ensure balancing,\n",
    "this can be done reasonably efficiently. \n",
    "\n",
    "Among the negative aspects of immutable trees is high memory allocation overhead and\n",
    "also bad locality. Because different parts of the tree may be stored in principle in completely different parts of memory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
