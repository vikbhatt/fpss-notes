{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Scan Left\n",
    "Having seen parallel map and parallel fold\n",
    "\n",
    "map: apply function to each element\n",
    "\n",
    "*  `List(1,3,8).map(x => x*x) == List(1, 9, 64)`\n",
    "\n",
    "fold: combine elements with a given operation\n",
    "\n",
    "* `List(1,3,8).fold(100)((s,x) => s + x) == 112`\n",
    "\n",
    "we now examine parallel scanLeft:\n",
    "\n",
    "scanLeft: list of the folds of all list prefixes\n",
    "\n",
    "`List(1,3,8).scanLeft(100)((s,x) => s + x) == List(100, 101, 104, 112)`\n",
    "\n",
    "`List(1,3,8).scanLeft(100)(_ + _) == List(100, 101, 104, 112)`\n",
    "\n",
    "`List(a1, a2, a3).scanLeft(f)(a0) = List(b0, b1, b2, b3)`\n",
    "\n",
    "where\n",
    "* $b0 = a0$\n",
    "* $b1 = f(b0, a1)$\n",
    "* $b2 = f(b1, a2)$\n",
    "* $b3 = f(b2, a3)$\n",
    "We assume that `f` is assocative, throughout this segment.\n",
    "\n",
    "`scanRight` is different from `scanLeft`, even if `f` is associative\n",
    "\n",
    "`List(1,3,8).scanRight(100)(_ + _) == List(112, 111, 108, 100)`\n",
    "\n",
    "We consider only `scanLeft`, but `scanRight` is dual.\n",
    "\n",
    "## Sequential Definition\n",
    "\n",
    "`List(a1, a2, ..., aN).scanLeft(f)(a0) = List(b0, b1, b2, ..., bN)`\n",
    "\n",
    "where $b_0 = a_0$ and $b_i = f(b_{i−1}, a_i)$ for $1 ≤ i ≤ N$.\n",
    "Give a sequential definition of `scanLeft`:\n",
    "\n",
    "* take an array `inp`, an element `a0`, and binary operation `f`\n",
    "* write the output to array `out`, assuming `out.length >= inp.length + 1`\n",
    "```scala\n",
    "def scanLeft[A](inp: Array[A], a0: A, f: (A,A) => A,out: Array[A]): Unit\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mscanLeft\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scanLeft[A](inp: Array[A],\n",
    "a0: A, f: (A,A) => A,\n",
    "out: Array[A]): Unit = {\n",
    "out(0)= a0\n",
    "var a= a0\n",
    "var i= 0\n",
    "while (i < inp.length) {\n",
    "a= f(a,inp(i))\n",
    "i= i + 1\n",
    "out(i)= a\n",
    "}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can `scanLeft` be made parallel? Assume that `f` is associative.\n",
    "\n",
    "Goal: an algorithm that runs in $\\mathcal{O}(\\log n)$ given infinite parallelism.\n",
    "\n",
    "\n",
    "At first, the task seems impossible; it seems that:\n",
    "* the value of the last element in sequence depends on all previous ones\n",
    "* need to wait on all previous partial results to be computed first\n",
    "* such approach gives $\\mathcal{O}(n)$ even with infinite parallelism\n",
    "\n",
    "\n",
    "> Idea: give up on reusing all intermediate results\n",
    " * do more work (more `f` applications)\n",
    " * improve parallelism, more than compensate for recomputation\n",
    " \n",
    " \n",
    "Can you define result of `scanLeft` using `map` and `reduce`?\n",
    "\n",
    "Assume input is given in array `inp` and that you have `reduceSeg1` and `mapSeg` functions on array segments:\n",
    "```scala\n",
    "def reduceSeg1[A](inp: Array[A], left: Int, right: Int, a0: Int, f: (A,A) => A): A\n",
    "\n",
    "def mapSeg[A,B](inp: Array[A], left: Int, right: Int, fi : (Int,A) => B, out: Array[B]): Unit\n",
    "```\n",
    "\n",
    "Assume that the input is given in the input array `inp`. And the boundaries of the segment that we are interested in are given by `left` and `right`. The initial element is `a0`, and the binary operation is `f`. \n",
    "\n",
    "Then reduce is going to be used in order to simply reduce that segment of the area `A`, and we can also use `map` which can apply\n",
    "an operation on a given array segment and write the resulting output array. \n",
    "\n",
    "We're going to use a slightly modified variant of map where the function that determines the mapping is given\n",
    "not only the element `A`, the value of the given point of the array, but also the index at which the value is stored. \\\n",
    "\n",
    "Can you implement scan left with an invocation of map and reduce? \n",
    "\n",
    "Here's one solution, this solution follows the definition of SCAD. \n",
    "\n",
    "So element in position i in the output, is the result of reducing the segment of the input array up to that position. Therefore, the resulting array will be obtained using a map over the input array where this function fi given to map is in fact going to reduce the array segment from 0 to i. The invocation of map will fill in\n",
    "the output array With elements, starting from 0 and\n",
    "ending in including input length- 1. We then just need to write the final element of the output array. That final element is computed by\n",
    "taking the element before the final and combining it with the corresponding element of the input array. \n",
    "\n",
    "\n",
    "\n",
    "If map and reduce are implemented in parallel, and they each have $\\log N$ parallel complexity, then because map is applying all these\n",
    "individual operations in parallel, you can see that the overall depth\n",
    "is going to continue to be $\\log N$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous solution we do not reuse any computation.\n",
    "\n",
    "Can we reuse some of it?\n",
    "\n",
    "Recall that reduce proceeds by applying the operations in a tree\n",
    "\n",
    "Idea: save the intermediate results of this parallel computation.\n",
    "\n",
    "We first assume that input collection is also (another) tree.\n",
    "\n",
    "Trees storing our input collection only have values in leaves:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mTree\u001b[39m\n",
       "defined \u001b[32mclass\u001b[39m \u001b[36mLeaf\u001b[39m\n",
       "defined \u001b[32mclass\u001b[39m \u001b[36mNode\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sealed abstract class Tree[A]\n",
    "case class Leaf[A](a: A) extends Tree[A]\n",
    "case class Node[A](l: Tree[A], r: Tree[A]) extends Tree[A]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trees storing intermediate values also have (res) values in nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mTreeRes\u001b[39m\n",
       "defined \u001b[32mclass\u001b[39m \u001b[36mLeafRes\u001b[39m\n",
       "defined \u001b[32mclass\u001b[39m \u001b[36mNodeRes\u001b[39m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sealed abstract class TreeRes[A] { val res: A }\n",
    "case class LeafRes[A](override val res: A) extends TreeRes[A]\n",
    "case class NodeRes[A](l: TreeRes[A],\n",
    "override val res: A, r: TreeRes[A]) extends TreeRes[A]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you define reduceRes function that transforms Tree into TreeRes?\n",
    "\n",
    "Here's the signature of `reduceRes`. The implementation of\n",
    "a `reduceRes` is very simple. Leaves map to leaves with the same value. And nodes invoke the reduction on left and\n",
    "right subtree with the same operation. And then, we build the resulting node. The resulting node has these left and\n",
    "right subtrees, this component. But it also needs to store the new value. In order to obtain the new value,\n",
    "all we need to do is apply the given binary operation to\n",
    "the results of the left and right subtree. So, you can see that the resulting tree has the same shape as the original tree, we just have these additional values. And the root of the overall tree is in fact the value of reduce on our initial collection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce that preserves the computation tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mreduceRes\u001b[39m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reduceRes[A](t: Tree[A], f: (A,A) => A): TreeRes[A] = t match {\n",
    "case Leaf(v) => LeafRes(v)\n",
    "case Node(l, r) => {\n",
    "val (tL, tR) = (reduceRes(l, f), reduceRes(r, f))\n",
    "NodeRes(tL, f(tL.res, tR.res), tR)\n",
    "}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mt1\u001b[39m: \u001b[32mNode\u001b[39m[\u001b[32mInt\u001b[39m] = \u001b[33mNode\u001b[39m(\u001b[33mNode\u001b[39m(\u001b[33mLeaf\u001b[39m(\u001b[32m1\u001b[39m), \u001b[33mLeaf\u001b[39m(\u001b[32m3\u001b[39m)), \u001b[33mNode\u001b[39m(\u001b[33mLeaf\u001b[39m(\u001b[32m8\u001b[39m), \u001b[33mLeaf\u001b[39m(\u001b[32m50\u001b[39m)))\n",
       "\u001b[36mplus\u001b[39m: (\u001b[32mInt\u001b[39m, \u001b[32mInt\u001b[39m) => \u001b[32mInt\u001b[39m = ammonite.$sess.cmd4$Helper$$Lambda$2052/0x9b467828@3d4a71\n",
       "\u001b[36mres0\u001b[39m: \u001b[32mTreeRes\u001b[39m[\u001b[32mInt\u001b[39m] = \u001b[33mNodeRes\u001b[39m(\n",
       "  \u001b[33mNodeRes\u001b[39m(\u001b[33mLeafRes\u001b[39m(\u001b[32m1\u001b[39m), \u001b[32m4\u001b[39m, \u001b[33mLeafRes\u001b[39m(\u001b[32m3\u001b[39m)),\n",
       "  \u001b[32m62\u001b[39m,\n",
       "  \u001b[33mNodeRes\u001b[39m(\u001b[33mLeafRes\u001b[39m(\u001b[32m8\u001b[39m), \u001b[32m58\u001b[39m, \u001b[33mLeafRes\u001b[39m(\u001b[32m50\u001b[39m))\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val t1 = Node(Node(Leaf(1), Leaf(3)), Node(Leaf(8), Leaf(50)))\n",
    "val plus = (x:Int,y:Int) => x+y\n",
    "val res0 = reduceRes(t1, plus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we would like to do this computation in parallel, but all we need to do in order to accomplish that is to insert this `parallel` keyword in front of the two recursive invocations. The resulting function, we will call `upsweep`. This suggests the bottom up\n",
    "computation that we use in order to obtain the tree of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mjava.util.concurrent._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.util.DynamicVariable\n",
       "  \n",
       "\u001b[39m\n",
       "\u001b[36mforkJoinPool\u001b[39m: \u001b[32mForkJoinPool\u001b[39m = java.util.concurrent.ForkJoinPool@1d5af79[Running, parallelism = 8, size = 0, active = 0, running = 0, steals = 0, tasks = 0, submissions = 0]\n",
       "defined \u001b[32mclass\u001b[39m \u001b[36mTaskScheduler\u001b[39m\n",
       "defined \u001b[32mclass\u001b[39m \u001b[36mDefaultTaskScheduler\u001b[39m\n",
       "\u001b[36mscheduler\u001b[39m: \u001b[32mDynamicVariable\u001b[39m[\u001b[32mTaskScheduler\u001b[39m] = DynamicVariable(ammonite.$sess.cmd5$Helper$DefaultTaskScheduler@16d737a)\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mtask\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mparallel\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mparallel\u001b[39m"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import java.util.concurrent._\n",
    "import scala.util.DynamicVariable\n",
    "  \n",
    "val forkJoinPool = new ForkJoinPool\n",
    "\n",
    "  abstract class TaskScheduler {\n",
    "    def schedule[T](body: => T): ForkJoinTask[T]\n",
    "    def parallel[A, B](taskA: => A, taskB: => B): (A, B) = {\n",
    "      val right = task {\n",
    "        taskB\n",
    "      }\n",
    "      val left = taskA\n",
    "      (left, right.join())\n",
    "    }\n",
    "  }\n",
    "\n",
    "  class DefaultTaskScheduler extends TaskScheduler {\n",
    "    def schedule[T](body: => T): ForkJoinTask[T] = {\n",
    "      val t = new RecursiveTask[T] {\n",
    "        def compute = body\n",
    "      }\n",
    "      Thread.currentThread match {\n",
    "        case wt: ForkJoinWorkerThread =>\n",
    "          t.fork()\n",
    "        case _ =>\n",
    "          forkJoinPool.execute(t)\n",
    "      }\n",
    "      t\n",
    "    }\n",
    "  }\n",
    "\n",
    "  val scheduler =\n",
    "    new DynamicVariable[TaskScheduler](new DefaultTaskScheduler)\n",
    "\n",
    "  def task[T](body: => T): ForkJoinTask[T] = {\n",
    "    scheduler.value.schedule(body)\n",
    "  }\n",
    "\n",
    "  def parallel[A, B](taskA: => A, taskB: => B): (A, B) = {\n",
    "    scheduler.value.parallel(taskA, taskB)\n",
    "  }\n",
    "\n",
    "  def parallel[A, B, C, D](taskA: => A, taskB: => B, taskC: => C, taskD: => D): (A, B, C, D) = {\n",
    "    val ta = task { taskA }\n",
    "    val tb = task { taskB }\n",
    "    val tc = task { taskC }\n",
    "    val td = taskD\n",
    "    (ta.join(), tb.join(), tc.join(), td)\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel reduce that preserves the computation tree (upsweep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mupsweep\u001b[39m"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def upsweep[A](t: Tree[A], f: (A,A) => A): TreeRes[A] = t match {\n",
    "case Leaf(v) => LeafRes(v)\n",
    "case Node(l, r) => {\n",
    "val (tL, tR) = parallel(upsweep(l, f), upsweep(r, f))\n",
    "NodeRes(tL, f(tL.res, tR.res), tR)\n",
    "}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given this tree with results, we would now like to produce\n",
    "the scanLeft of our initial collection. For the collection 1, 3, 8,\n",
    "50 and the initial element 100, the scanLeft should be the following list. \n",
    "\n",
    "The computation of `scanLeft`, given\n",
    "the result tree from `upSweep`, is called `downsweep`. Downsweep takes an initial element `a0`, which plays an important role here. And the tree of results. And the binary operation `f`. It will produce a new collection,just like the bigger tree in the end. We will first produce a tree that has the same length as the original one. To understand how downsweep works, the key fact to remember is that a0 is supposed to denote the reduce of all elements that come to the left of\n",
    "the current tree, t, that we are given. \n",
    "\n",
    "\n",
    "\n",
    "At the very beginning,\n",
    "this is the initial element, 100. As we move down the tree,\n",
    "then we get some elements that proceeded. So, for example, for this subtree here. What we need to take into account is 100,\n",
    "1, and 3. When we have the Leaf, then,\n",
    "we simply need to apply operation f to the given element a0 and\n",
    "the element in the Leaf. The interesting case is\n",
    "of course case of Node. We are going to again recursively do\n",
    "a downsweep on the left and right subtree. This will give us two new trees, left and\n",
    "right, and then, we will combine it. The key question is, what is the initial element that we\n",
    "are passing to these two subtrees? Now, what are the things that are to\n",
    "the left of our left subtree here? Well, they are the things that\n",
    "they are left to the entire tree. So, we are passing the same element a0. What about the right subtree? Here, we need to take into account both\n",
    "the elements that we are given, a0. But also,\n",
    "what happened in the left subtree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using tree with results to create the final collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mdownsweep\u001b[39m"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def downsweep[A](t: TreeRes[A], a0: A, f : (A,A) => A): Tree[A] = t match {\n",
    "case LeafRes(a) => Leaf(f(a0, a))\n",
    "case NodeRes(l, _, r) => {\n",
    "val (tL, tR) = parallel(downsweep[A](l, a0, f),\n",
    "downsweep[A](r, f(a0, l.res), f))\n",
    "Node(tL, tR) } }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand how downsweep works, remember `a0` is used to denote the reduce of all elements that come to the left of current tree `t`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres8\u001b[39m: \u001b[32mTree\u001b[39m[\u001b[32mInt\u001b[39m] = \u001b[33mNode\u001b[39m(\u001b[33mNode\u001b[39m(\u001b[33mLeaf\u001b[39m(\u001b[32m101\u001b[39m), \u001b[33mLeaf\u001b[39m(\u001b[32m104\u001b[39m)), \u001b[33mNode\u001b[39m(\u001b[33mLeaf\u001b[39m(\u001b[32m112\u001b[39m), \u001b[33mLeaf\u001b[39m(\u001b[32m162\u001b[39m)))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downsweep(res0, 100, plus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the reuslt of `scanLeft` using the functions defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mscanLeft\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mprepend\u001b[39m"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scanLeft[A](t: Tree[A], a0: A, f: (A,A) => A): Tree[A] = {\n",
    "val tRes = upsweep(t, f)\n",
    "val scan1 = downsweep(tRes, a0, f)\n",
    "prepend(a0, scan1)\n",
    "}\n",
    "def prepend[A](x: A, t: Tree[A]): Tree[A] = t match {\n",
    "case Leaf(v) => Node(Leaf(x), Leaf(v))\n",
    "case Node(l, r) => Node(prepend(x, l), r)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres10\u001b[39m: \u001b[32mTree\u001b[39m[\u001b[32mInt\u001b[39m] = \u001b[33mNode\u001b[39m(\n",
       "  \u001b[33mNode\u001b[39m(\u001b[33mNode\u001b[39m(\u001b[33mLeaf\u001b[39m(\u001b[32m100\u001b[39m), \u001b[33mLeaf\u001b[39m(\u001b[32m101\u001b[39m)), \u001b[33mLeaf\u001b[39m(\u001b[32m104\u001b[39m)),\n",
       "  \u001b[33mNode\u001b[39m(\u001b[33mLeaf\u001b[39m(\u001b[32m112\u001b[39m), \u001b[33mLeaf\u001b[39m(\u001b[32m162\u001b[39m))\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scanLeft(t1, 100, plus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous definition on trees is good for understanding\n",
    "\n",
    "As with `map` and `reduce`, to make it more efficient, we use trees that have arrays in leaves instead of individual elements.\n",
    "Exercise: define `scanLeft` on trees with such large leaves, using sequential scan left in the leaves.\n",
    "\n",
    "Next step: parallel scan when the entire collection is an array\n",
    "\n",
    "▶ we will still need to construct the intermediate tree\n",
    "\n",
    "Now we go further and examine parallel scan for a collection represented as an array. So we have one big array to start with. Interestingly even in this case we use tree to store intermediate results. The tree of intermediate results looks very similar to the one we seen before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mTreeResA\u001b[39m\n",
       "defined \u001b[32mclass\u001b[39m \u001b[36mLeaf\u001b[39m\n",
       "defined \u001b[32mclass\u001b[39m \u001b[36mNode\u001b[39m"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sealed abstract class TreeResA[A] { val res: A }\n",
    "case class Leaf[A](from: Int, to: Int,\n",
    "override val res: A) extends TreeResA[A]\n",
    "case class Node[A](l: TreeResA[A], \n",
    "override val res: A, r: TreeResA[A]) extends TreeResA[A]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Node` stores left and right subtree, as well as the value we computed. On the other hand there is small change in leaves. We want to process our arrays efficiently, we want to stop when the chunks processing are small enough. We represent these chunks using indices `from` and `to`. We will not store the actual content, but we will store the indices to big array. We are storing indication where those values can be found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mthreshold\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m50\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mupsweep\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mreduceSeg1\u001b[39m"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val threshold = 50\n",
    "def upsweep[A](inp: Array[A], from: Int, to: Int,\n",
    "f: (A,A) => A): TreeResA[A] = {\n",
    "if (to - from < threshold)\n",
    "Leaf(from, to, reduceSeg1(inp, from + 1, to, inp(from), f))\n",
    "else {\n",
    "val mid = from + (to - from)/2\n",
    "val (tL,tR) = parallel(upsweep(inp, from, mid, f),\n",
    "upsweep(inp, mid, to, f))\n",
    "Node(tL, f(tL.res,tR.res), tR)\n",
    "}\n",
    "}\n",
    "\n",
    "def reduceSeg1[A](inp: Array[A], left: Int, right: Int,\n",
    "a0: A, f: (A,A) => A): A = {\n",
    "var a= a0\n",
    "var i= left\n",
    "while (i < right) {\n",
    "a= f(a, inp(i))\n",
    "i= i+1\n",
    "}\n",
    "a\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mscanLeftSeg\u001b[39m"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scanLeftSeg[A](inp: Array[A], left: Int, right: Int,\n",
    "a0: A, f: (A,A) => A,\n",
    "out: Array[A]) = {\n",
    "if (left < right) {\n",
    "var i= left\n",
    "var a= a0\n",
    "while (i < right) {\n",
    "a= f(a,inp(i))\n",
    "i= i+1\n",
    "out(i)=a\n",
    "}\n",
    "}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mdownsweep\u001b[39m"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def downsweep[A](inp: Array[A],\n",
    "a0: A, f: (A,A) => A,\n",
    "t: TreeResA[A],\n",
    "out: Array[A]): Unit = t match {\n",
    "case Leaf(from, to, res) =>\n",
    "scanLeftSeg(inp, from, to, a0, f, out)\n",
    "case Node(l, _, r) => {\n",
    "val (_,_) = parallel(\n",
    "downsweep(inp, a0, f, l, out),\n",
    "downsweep(inp, f(a0,l.res), f, r, out))\n",
    "}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mscanLeft\u001b[39m"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scanLeft[A](inp: Array[A],\n",
    "a0: A, f: (A,A) => A,\n",
    "out: Array[A]) = {\n",
    "val t = upsweep(inp, 0, inp.length, f)\n",
    "downsweep(inp, a0, f, t, out) // fills out[1..inp.length]\n",
    "out(0)= a0 // prepends a0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36minp\u001b[39m: \u001b[32mArray\u001b[39m[\u001b[32mInt\u001b[39m] = \u001b[33mArray\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m)\n",
       "\u001b[36mout\u001b[39m: \u001b[32mArray\u001b[39m[\u001b[32mInt\u001b[39m] = \u001b[33mArray\u001b[39m(\u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m, \u001b[32m7\u001b[39m, \u001b[32m10\u001b[39m)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val inp = Array(1,2,3)\n",
    "val out = Array(1,1,1,1)\n",
    "scanLeft(inp ,4,(x:Int, y:Int)=> x+y, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres18\u001b[39m: \u001b[32mArray\u001b[39m[\u001b[32mInt\u001b[39m] = \u001b[33mArray\u001b[39m(\u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m, \u001b[32m7\u001b[39m, \u001b[32m10\u001b[39m)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
